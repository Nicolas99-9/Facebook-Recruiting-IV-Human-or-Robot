{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "def load_data_set():\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test[\"outcome\"] = 9\n",
    "    bids = pd.read_csv('bids.csv')\n",
    "    bids = bids.sort(['auction', 'time'])\n",
    "    return train_data,bids,test\n",
    "\n",
    "train,bids,test = load_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to detect a bot ?\\nSame ip\\nFast biding\\nBid faster than human\\n#\\naverage time between two bids\\ntime since bid starting\\nnumber of bids\\nmax time\\n\\nfaire par rapport aux autres utilisateurs et faire par rapport a lui meme\\naverage number of bids per auction\\nmax number of bids per auction\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Alors fonction generer pour les bids l'ensemble des donnees suivantes : \n",
    "Pour chaque vente : temps moyen,max, std et min entre deux bids d une meme personne\n",
    "                    temps moyen,max, st entre deux bids\n",
    "                    nombre de bids max, min, et moyen de chaque utilisateur \n",
    "sauvegarde des resultats dans 3 csv differents\n",
    "'''\n",
    "def time_into_auction(train,bids,test):\n",
    "    human = train[train.outcome==0].bidder_id\n",
    "    bot = train[train.outcome==1].bidder_id\n",
    "    grouped = bids.groupby('auction')\n",
    "    done = -5\n",
    "    #temps de bid par rapport aux dans une meme vente\n",
    "    times_df = {}\n",
    "    #temps de bid par rapport a soit meme pour chaque vente\n",
    "    bid_himselft = {}\n",
    "    #number of bids:\n",
    "    number_bids = {}\n",
    "    #wins auctions\n",
    "    wins_auctions = {}\n",
    "    moments_bids_final = {}\n",
    "    remaining = len(grouped)\n",
    "    for bides in grouped:\n",
    "        sub_data= bides[1]\n",
    "        difference=  [0,0]\n",
    "        last_bids = {}\n",
    "        current_bids = {}\n",
    "        start = 0\n",
    "        end  = 0\n",
    "        has_win = -1\n",
    "        moments_bids = {}\n",
    "        for acc in sub_data.iterrows():\n",
    "            i,line = acc\n",
    "            cle = line['bidder_id']\n",
    "            if difference[0] == 0:\n",
    "                difference[0] = line['time']\n",
    "                start = line['time']\n",
    "            else:\n",
    "                if not cle in times_df:\n",
    "                    times_df[cle] = []\n",
    "                times_df[cle].append(line['time']-difference[0])\n",
    "                difference[0] = line['time']\n",
    "            if cle not in moments_bids:\n",
    "                moments_bids[cle]= [line['time']]\n",
    "            else:\n",
    "                moments_bids[cle].append(line['time'])\n",
    "            if cle not in last_bids:\n",
    "                last_bids[cle] = (line['time'],[])\n",
    "            else:\n",
    "                last_bids[cle][1].append(line['time']-last_bids[cle][0])\n",
    "                last_bids[cle] = (line['time'],last_bids[cle][1])\n",
    "            if cle not in current_bids:\n",
    "                current_bids[cle] = 1\n",
    "            else:\n",
    "                current_bids[cle] +=1\n",
    "            end = line['time']\n",
    "            has_win = cle\n",
    "        #fusion des dictionnaires\n",
    "        for c in current_bids:\n",
    "            if not c in number_bids:\n",
    "                number_bids[c] = [current_bids[c]]\n",
    "            else:\n",
    "                number_bids[c].append(current_bids[c])\n",
    "        for c in last_bids:\n",
    "            if not c in bid_himselft and len(last_bids[c][1])>0:\n",
    "                bid_himselft[c] = last_bids[c]\n",
    "            elif  len(last_bids[c][1])>0:\n",
    "                bid_himselft[c] += last_bids[c]\n",
    "        for c in moments_bids:\n",
    "            if c not in moments_bids_final:\n",
    "                moments_bids_final[c] = []\n",
    "            moments_bids_final[c] += [((od-start)/float((end-start)+1.0)) for od in moments_bids[c]]\n",
    "        loose = sub_data[\"bidder_id\"].unique()\n",
    "        for c in loose:\n",
    "            if c not in wins_auctions:\n",
    "                wins_auctions[c] = [0,0]\n",
    "            wins_auctions[c][has_win==c] +=1\n",
    "        if remaining %200 ==0:\n",
    "            print(\"remaining : \", remaining)\n",
    "        remaining -=1\n",
    "    df = []\n",
    "    for c in wins_auctions:\n",
    "        wins_auctions[c] = wins_auctions[c][1] / float(np.sum(wins_auctions[c]))\n",
    "    for cle in times_df.keys():\n",
    "        df.append({'bidder_id': cle, 'mean_autres': np.mean(times_df[cle]),\n",
    "    'min_autres': np.min(times_df[cle]), 'max_autres': np.max(times_df[cle]),'std_autres': np.std(times_df[cle])})\n",
    "    pd.DataFrame(df).to_csv('res/time_auction.csv', index=False)\n",
    "    df = []\n",
    "    for cle in number_bids.keys():\n",
    "        df.append({'bidder_id': cle, 'mean_number_bids': np.mean(number_bids[cle]),\n",
    "    'min_number_bids': np.min(number_bids[cle]), 'max_number_bids': np.max(number_bids[cle]),\n",
    "    'number_bids': len(number_bids[cle]),'std_number_bids': np.std(number_bids[cle])})\n",
    "    pd.DataFrame(df).to_csv('res/bids_number.csv', index=False)\n",
    "    df  = []\n",
    "    for cle in bid_himselft.keys():\n",
    "        val = bid_himselft[cle][1]\n",
    "        df.append({'bidder_id': cle, 'mean_time_bids': np.mean(val),\n",
    "    'min_time bids': np.min(val), 'max_time_bids': np.max(val),\n",
    "    'number_of_auctions_bids': len(val),'std_time_bids': np.std(val)})\n",
    "    pd.DataFrame(df).to_csv('res/himslef_time.csv', index=False)\n",
    "    df  = []\n",
    "    for cle in moments_bids_final.keys():\n",
    "        #10 percent starting :\n",
    "        #10 percent ending :\n",
    "        starting = [(fre<0.1) for fre in moments_bids_final[cle]]\n",
    "        ending = [(fre>0.9) for fre in moments_bids_final[cle]]\n",
    "        #print(moments_bids_final[cle][moments_bids_final[cle]>0.10])\n",
    "        df.append({'bidder_id': cle, 'average_moment_bid': np.mean(moments_bids_final[cle]),\n",
    "    'std_moment_bid':np.std(moments_bids_final[cle]),'frequence_wind':wins_auctions[cle], 'starting_quick' : float(np.sum(starting))/float(len(starting)),\n",
    "        'ending_quick' : float(np.sum(ending))/float(len(ending))})\n",
    "    pd.DataFrame(df).to_csv('res/other_stats.csv', index=False)\n",
    "    \n",
    "\n",
    "recreate_feature = False\n",
    "if recreate_feature:\n",
    "    time_into_auction(train,bids,test)\n",
    "\n",
    "'''How to detect a bot ?\n",
    "Same ip\n",
    "Fast biding\n",
    "Bid faster than human\n",
    "#\n",
    "average time between two bids\n",
    "time since bid starting\n",
    "number of bids\n",
    "max time\n",
    "\n",
    "faire par rapport aux autres utilisateurs et faire par rapport a lui meme\n",
    "average number of bids per auction\n",
    "max number of bids per auction\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path\n",
    "\n",
    "def normalize(dicts):\n",
    "    for c in dicts:\n",
    "        tmp = dicts[c]\n",
    "        total = float(np.sum(tmp))\n",
    "        dicts[c] = (tmp[0]/total,tmp[1]/total)\n",
    "    return dicts\n",
    "# generate the features using the features created before\n",
    "def feature_creation(train,test,bids):\n",
    "    #number of differents ips,urls\n",
    "    grouped = bids.groupby(['bidder_id','auction'])\n",
    "    '''app_mean = grouped.device.nunique().groupby(level=0).mean()\n",
    "    app_std = grouped.device.nunique().groupby(level=0).std()\n",
    "    app_max = grouped.device.nunique().groupby(level=0).max()\n",
    "    ip_mean = grouped.ip.nunique().groupby(level=0).mean()\n",
    "    ip_std = grouped.ip.nunique().groupby(level=0).std()\n",
    "    ip_max = grouped.ip.nunique().groupby(level=0).max()\n",
    "    pays_mean = grouped.country.nunique().groupby(level=0).mean()\n",
    "    pays_std = grouped.country.nunique().groupby(level=0).std()\n",
    "    pays_max = grouped.country.nunique().groupby(level=0).max()\n",
    "    page_mean = grouped.url.nunique().groupby(level=0).mean()\n",
    "    page_std = grouped.url.nunique().groupby(level=0).std()\n",
    "    page_max = grouped.url.nunique().groupby(level=0).max()'''\n",
    "    #hour in the day for the humans and for each country \n",
    "    human = train[train.outcome==0]\n",
    "    bots = train[train.outcome==1]\n",
    "    human_bids = bids[bids[\"bidder_id\"].isin(human[\"bidder_id\"])]\n",
    "    robot_bids = bids[bids[\"bidder_id\"].isin(bots[\"bidder_id\"])]\n",
    "    show_stats = False\n",
    "    if show_stats:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sn\n",
    "        %matplotlib inline\n",
    "        countries = bids[\"country\"].unique()\n",
    "        for c in countries:\n",
    "            sub_d_h= human_bids[human_bids[\"country\"] == c]\n",
    "            sub_d_r= robot_bids[robot_bids[\"country\"] == c]\n",
    "            if len(sub_d_r)>1:\n",
    "                tmp_plot = sub_d_h.groupby(\"time\").count()\n",
    "                tmp_plot2 = sub_d_r.groupby(\"time\").count()\n",
    "                plt.plot(tmp_plot.index,tmp_plot,label=\"human\",alpha=0.7)\n",
    "                plt.plot(tmp_plot2.index,tmp_plot2,label=\"robot\",alpha=0.7)\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    #average moment of biding in the auction and win percentage\n",
    "    countries = {}\n",
    "    urls = {}\n",
    "    devices = {}\n",
    "    ips = {}\n",
    "    auctions = {}\n",
    "    merchandises = {}\n",
    "    times = {}\n",
    "    if os.path.exists(\"stats/urls.pkl\"):\n",
    "        with open('stats/urls.pkl', 'rb') as handle:\n",
    "            urls = pickle.load(handle)\n",
    "        with open('stats/countries.pkl', 'rb') as handle:\n",
    "            countries = pickle.load(handle)\n",
    "        with open('stats/devices.pkl', 'rb') as handle:\n",
    "            devices = pickle.load(handle)\n",
    "        with open('stats/merchandises.pkl', 'rb') as handle:\n",
    "            merchandises = pickle.load(handle)\n",
    "        with open('stats/auctions.pkl', 'rb') as handle:\n",
    "            auctions = pickle.load(handle)\n",
    "        with open('stats/times.pkl', 'rb') as handle:\n",
    "            times = pickle.load(handle)\n",
    "        print(len(auctions),len(times),len(merchandises),len(devices),len(countries),len(urls))\n",
    "    else:\n",
    "        to_do = len(bids)\n",
    "        bots_values = bots[\"bidder_id\"].values\n",
    "        #basics stats\n",
    "        for i,acc in bids.iterrows():\n",
    "            url = acc[\"url\"]\n",
    "            country = acc[\"country\"]\n",
    "            device = acc[\"device\"]\n",
    "            bid = acc[\"auction\"]\n",
    "            merchan = acc[\"merchandise\"]\n",
    "            time = acc[\"time\"]\n",
    "            cle = acc[\"bidder_id\"]\n",
    "            bot = cle in bots_values\n",
    "            if url not in urls:\n",
    "                urls[url] = [0,0]\n",
    "            if country not in countries:\n",
    "                countries[country] = [0,0]\n",
    "            if device not in devices:\n",
    "                devices[device] = [0,0]\n",
    "            if bid not in auctions:\n",
    "                auctions[bid] = [0,0]\n",
    "            if merchan not in merchandises:\n",
    "                merchandises[merchan] = [0,0]\n",
    "            if time not in times:\n",
    "                times[time] = [0,0]\n",
    "            if bot:\n",
    "                urls[url][0] +=1\n",
    "                countries[country][0] +=1\n",
    "                devices[device][0] +=1\n",
    "                merchandises[merchan][0] +=1\n",
    "                auctions[bid][0] +=1\n",
    "                times[time][0] +=1\n",
    "            else:\n",
    "                urls[url][1] +=1\n",
    "                countries[country][1] +=1\n",
    "                devices[device][1] +=1\n",
    "                merchandises[merchan][1] +=1\n",
    "                auctions[bid][1] +=1\n",
    "                times[time][1] +=1 \n",
    "            to_do -= 1\n",
    "            if to_do % 100000 ==0:\n",
    "                print(to_do)\n",
    "        urls = normalize(urls)\n",
    "        countries = normalize(countries)\n",
    "        devices = normalize(devices)\n",
    "        merchandises = normalize(merchandises)\n",
    "        auctions = normalize(auctions)\n",
    "        times = normalize(times)\n",
    "        with open('stats/urls.pkl', 'wb') as handle:\n",
    "            pickle.dump(urls, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/countries.pkl', 'wb') as handle:\n",
    "            pickle.dump(countries, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/devices.pkl', 'wb') as handle:\n",
    "            pickle.dump(devices, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/merchandises.pkl', 'wb') as handle:\n",
    "            pickle.dump(merchandises, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/auctions.pkl', 'wb') as handle:\n",
    "            pickle.dump(auctions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/times.pkl', 'wb') as handle:\n",
    "            pickle.dump(times, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    grouped_person = bids.groupby(['bidder_id'])\n",
    "    url_score = {}\n",
    "    country_score = {}\n",
    "    merchan_score = {}\n",
    "    devices_score = {}\n",
    "    auct_score = {}\n",
    "    times_score = {}\n",
    "    remaining = len(grouped_person)\n",
    "    print(\"TO DO : \",remaining)\n",
    "    bots_values = bots[\"bidder_id\"].values\n",
    "    for bides in grouped_person:\n",
    "        sub_data= bides[1]\n",
    "        for i,acc in sub_data.iterrows():\n",
    "            cle = acc[\"bidder_id\"]\n",
    "            bot = cle in bots_values\n",
    "            if cle not in url_score:\n",
    "                url_score[cle] = urls[acc[\"url\"]][int(bot)]\n",
    "            if cle not in country_score:\n",
    "                cle_c = acc[\"country\"]\n",
    "                if acc[\"country\"] != \"nan\":\n",
    "                    cle_c = \"in\"\n",
    "                country_score[cle] = countries[cle_c][int(bot)]\n",
    "            if cle not in merchan_score:\n",
    "                merchan_score[cle] = merchandises[acc[\"merchandise\"]][int(bot)]\n",
    "            if cle not in devices_score:\n",
    "                devices_score[cle] = devices[acc[\"device\"]][int(bot)]\n",
    "            if cle not in auct_score:\n",
    "                auct_score[cle] = auctions[acc[\"auction\"]][int(bot)]\n",
    "            if cle not in times_score:\n",
    "                times_score[cle] = times[acc[\"time\"]][int(bot)]\n",
    "        url_score[cle] = url_score[cle]  /float(len(sub_data))\n",
    "        country_score[cle] = country_score[cle]  /float(len(sub_data))\n",
    "        devices_score[cle] = devices_score[cle]  /float(len(sub_data))\n",
    "        merchan_score[cle] = merchan_score[cle]  /float(len(sub_data))\n",
    "        auct_score[cle] = auct_score[cle]  /float(len(sub_data))\n",
    "        times_score[cle] = times_score[cle]  /float(len(sub_data))\n",
    "        if remaining % 500 ==0:\n",
    "            print(remaining)\n",
    "        remaining -=1\n",
    "    df  = []\n",
    "    for cle in url_score.keys():\n",
    "        df.append({'bidder_id' : cle, 'url_score': url_score[cle], 'country_score': country_score[cle],\n",
    "    'device_score': devices_score[cle], 'merchan_score': merchan_score[cle],\n",
    "    'zauc_score': auct_score[cle],'time_score': times_score[cle]})\n",
    "    pd.DataFrame(df).to_csv('res/scores.csv', index=False)\n",
    "    \n",
    "    #to do : total number of bids, max nombre de bids dans une fentre de 15 minutes\n",
    "    #nombre de bids pour chacun des jours\n",
    "    '''\n",
    "    heure moyen de bid\n",
    "    number of simulatneous bids\n",
    "    est ce que c'est une heire normale (calculer pour chaque pays fenetre la plus utilisee dans la journee)\n",
    "    appartenir a url ? 'vasstdc27m7nks3(proba)\n",
    "    '''\n",
    "recreate = False\n",
    "if recreate:\n",
    "    feature_creation(train,test,bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_all(train,test,bids):\n",
    "    bids_numbers = pd.read_csv('res/bids_number.csv')\n",
    "    himself_time = pd.read_csv('res/himslef_time.csv')\n",
    "    other = pd.read_csv('res/other_stats.csv')\n",
    "    scores = pd.read_csv('res/scores.csv')\n",
    "    time_auction = pd.read_csv('res/time_auction.csv')\n",
    "    #test file\n",
    "    y_train = train[\"outcome\"]\n",
    "    #new train representation\n",
    "    new_train = train[\"bidder_id\"].to_frame()\n",
    "    new_train = new_train.merge(bids_numbers,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = new_train.merge(himself_time,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = new_train.merge(other,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = new_train.merge(scores,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = new_train.merge(time_auction,on=\"bidder_id\",how=\"left\")\n",
    "    new_train= new_train.fillna(new_train.mean())\n",
    "    #new test\n",
    "    new_test = test[\"bidder_id\"].to_frame()\n",
    "    new_test = new_test.merge(bids_numbers,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = new_test.merge(himself_time,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = new_test.merge(other,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = new_test.merge(scores,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = new_test.merge(time_auction,on=\"bidder_id\",how=\"left\")\n",
    "    new_test= new_test.fillna(new_test.mean())\n",
    "    return new_train,new_test,y_train\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "X_train,X_test,y_train = load_all(train,test,bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Score : ', 0.9286910994764398)\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "# first ml algo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def cross_val(X_train,X_test,y_train):\n",
    "    X_train_bis = X_train.drop(\"bidder_id\",axis=1).values\n",
    "    X_test_bis = X_test.drop(\"bidder_id\",axis=1).values\n",
    "    y_train_bis = y_train.astype(int).values\n",
    "    predictions = []\n",
    "    kf = StratifiedKFold(y=y_train, n_folds=10)\n",
    "    clf = RandomForestClassifier(n_estimators=60, max_features=20,max_depth=8, random_state=9,criterion='entropy')\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X_train_bis[train_index], X_train_bis[test_index]\n",
    "        y_train, y_test = y_train_bis[train_index], y_train_bis[test_index]\n",
    "        clf.fit(X_train,y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        predictions.append(roc_auc_score(y_test, prediction))\n",
    "    print(\"Score : \", np.mean(predictions))\n",
    "\n",
    "\n",
    "def fill_predcitions(X_train,X_test,y_train):\n",
    "    X_train_bis = X_train.drop(\"bidder_id\",axis=1).values\n",
    "    X_test_bis = X_test.drop(\"bidder_id\",axis=1).values\n",
    "    y_train_bis = y_train.astype(int).values\n",
    "    clf = RandomForestClassifier(n_estimators=60, max_features=20,max_depth=8, random_state=9,criterion='entropy')\n",
    "    clf.fit(X_train_bis,y_train_bis)\n",
    "    prediction = clf.predict(X_test_bis)\n",
    "    prediction = prediction.astype(float)\n",
    "    submi = pd.read_csv('sampleSubmission.csv')\n",
    "    submi[\"prediction\"] = prediction\n",
    "    submi.to_csv('submission/random.csv', index=False)\n",
    "    \n",
    "    \n",
    "cross_val(X_train,X_test,y_train)\n",
    "fill_predcitions(X_train,X_test,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
