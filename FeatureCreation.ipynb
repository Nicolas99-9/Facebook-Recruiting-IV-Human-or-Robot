{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data_set():\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test[\"outcome\"] = 9\n",
    "    bids = pd.read_csv('bids.csv')\n",
    "    #bids = bids.sort(['auction', 'time'])\n",
    "    return train_data,bids,test\n",
    "\n",
    "train,bids,test = load_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to detect a bot ?\\nSame ip\\nFast biding\\nBid faster than human\\n#\\naverage time between two bids\\ntime since bid starting\\nnumber of bids\\nmax time\\n\\nfaire par rapport aux autres utilisateurs et faire par rapport a lui meme\\naverage number of bids per auction\\nmax number of bids per auction\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Alors fonction generer pour les bids l'ensemble des donnees suivantes : \n",
    "Pour chaque vente : temps moyen,max, std et min entre deux bids d une meme personne\n",
    "                    temps moyen,max, st entre deux bids\n",
    "                    nombre de bids max, min, et moyen de chaque utilisateur \n",
    "sauvegarde des resultats dans 3 csv differents\n",
    "'''\n",
    "def time_into_auction(train,bids,test):\n",
    "    human = train[train.outcome==0].bidder_id\n",
    "    bot = train[train.outcome==1].bidder_id\n",
    "    grouped = bids.groupby('auction')\n",
    "    done = -5\n",
    "    #temps de bid par rapport aux dans une meme vente\n",
    "    times_df = {}\n",
    "    #temps de bid par rapport a soit meme pour chaque vente\n",
    "    bid_himselft = {}\n",
    "    #number of bids:\n",
    "    number_bids = {}\n",
    "    #wins auctions\n",
    "    wins_auctions = {}\n",
    "    moments_bids_final = {}\n",
    "    remaining = len(grouped)\n",
    "    difference=  [0,0]\n",
    "    for bides in grouped:\n",
    "        sub_data= bides[1]\n",
    "        #sub_data.sort(\"time\")\n",
    "        last_bids = {}\n",
    "        current_bids = {}\n",
    "        start = 0\n",
    "        end  = 0\n",
    "        has_win = -1\n",
    "        moments_bids = {}\n",
    "        for acc in sub_data.iterrows():\n",
    "            i,line = acc\n",
    "            cle = line['bidder_id']\n",
    "            if difference[0] == 0:\n",
    "                difference[0] = line['time']\n",
    "                start = line['time']\n",
    "            else:\n",
    "                if not cle in times_df:\n",
    "                    times_df[cle] = []\n",
    "                times_df[cle].append(line['time']-difference[0])\n",
    "                difference[0] = line['time']\n",
    "            if cle not in moments_bids:\n",
    "                moments_bids[cle]= [line['time']]\n",
    "            else:\n",
    "                moments_bids[cle].append(line['time'])\n",
    "            if cle not in last_bids:\n",
    "                last_bids[cle] = (line['time'],[])\n",
    "            else:\n",
    "                last_bids[cle][1].append(line['time']-last_bids[cle][0])\n",
    "                last_bids[cle] = (line['time'],last_bids[cle][1])\n",
    "            if cle not in current_bids:\n",
    "                current_bids[cle] = 1\n",
    "            else:\n",
    "                current_bids[cle] +=1\n",
    "            end = line['time']\n",
    "            has_win = cle\n",
    "        #fusion des dictionnaires\n",
    "        for c in current_bids:\n",
    "            if not c in number_bids:\n",
    "                number_bids[c] = [current_bids[c]]\n",
    "            else:\n",
    "                number_bids[c].append(current_bids[c])\n",
    "        for c in last_bids:\n",
    "            if not c in bid_himselft and len(last_bids[c][1])>0:\n",
    "                bid_himselft[c] = last_bids[c]\n",
    "            elif  len(last_bids[c][1])>0:\n",
    "                bid_himselft[c] += last_bids[c]\n",
    "        for c in moments_bids:\n",
    "            if c not in moments_bids_final:\n",
    "                moments_bids_final[c] = []\n",
    "            moments_bids_final[c] += [((od-start)/float((end-start)+1.0)) for od in moments_bids[c]]\n",
    "        loose = sub_data[\"bidder_id\"].unique()\n",
    "        for c in loose:\n",
    "            if c not in wins_auctions:\n",
    "                wins_auctions[c] = [0,0]\n",
    "            wins_auctions[c][has_win==c] +=1\n",
    "        if remaining %200 ==0:\n",
    "            print(\"remaining : \", remaining)\n",
    "        remaining -=1\n",
    "    df = []\n",
    "    for c in wins_auctions:\n",
    "        wins_auctions[c] = wins_auctions[c][1] / float(np.sum(wins_auctions[c]))\n",
    "    for cle in times_df.keys():\n",
    "        df.append({'bidder_id': cle, 'mean_autres': np.mean(times_df[cle]),\n",
    "    'min_autres': np.min(times_df[cle]), 'max_autres': np.max(times_df[cle]),'std_autres': np.std(times_df[cle])})\n",
    "    pd.DataFrame(df).to_csv('res/time_auction.csv', index=False)\n",
    "    df = []\n",
    "    for cle in number_bids.keys():\n",
    "        df.append({'bidder_id': cle, 'mean_number_bids': np.mean(number_bids[cle]),\n",
    "    'min_number_bids': np.min(number_bids[cle]), 'max_number_bids': np.max(number_bids[cle]),\n",
    "    'number_bids': len(number_bids[cle]),'std_number_bids': np.std(number_bids[cle])})\n",
    "    pd.DataFrame(df).to_csv('res/bids_number.csv', index=False)\n",
    "    df  = []\n",
    "    for cle in bid_himselft.keys():\n",
    "        val = bid_himselft[cle][1]\n",
    "        df.append({'bidder_id': cle, 'mean_time_bids': np.mean(val),\n",
    "    'min_time bids': np.min(val), 'max_time_bids': np.max(val),\n",
    "    'number_of_auctions_bids': len(val),'std_time_bids': np.std(val)})\n",
    "    pd.DataFrame(df).to_csv('res/himslef_time.csv', index=False)\n",
    "    df  = []\n",
    "    for cle in moments_bids_final.keys():\n",
    "        #10 percent starting :\n",
    "        #10 percent ending :\n",
    "        starting = [(fre<0.1) for fre in moments_bids_final[cle]]\n",
    "        ending = [(fre>0.9) for fre in moments_bids_final[cle]]\n",
    "        #print(moments_bids_final[cle][moments_bids_final[cle]>0.10])\n",
    "        df.append({'bidder_id': cle, 'average_moment_bid': np.mean(moments_bids_final[cle]),\n",
    "    'std_moment_bid':np.std(moments_bids_final[cle]),'frequence_wind':wins_auctions[cle], 'starting_quick' : float(np.sum(starting))/float(len(starting)),\n",
    "        'ending_quick' : float(np.sum(ending))/float(len(ending))})\n",
    "    pd.DataFrame(df).to_csv('res/other_stats.csv', index=False)\n",
    "    \n",
    "\n",
    "recreate_feature = False\n",
    "if recreate_feature:\n",
    "    time_into_auction(train,bids,test)\n",
    "\n",
    "'''How to detect a bot ?\n",
    "Same ip\n",
    "Fast biding\n",
    "Bid faster than human\n",
    "#\n",
    "average time between two bids\n",
    "time since bid starting\n",
    "number of bids\n",
    "max time\n",
    "\n",
    "faire par rapport aux autres utilisateurs et faire par rapport a lui meme\n",
    "average number of bids per auction\n",
    "max number of bids per auction\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path\n",
    "\n",
    "def normalize(dicts):\n",
    "    for c in dicts:\n",
    "        tmp = dicts[c]\n",
    "        total = float(np.sum(tmp))\n",
    "        dicts[c] = (tmp[0]/total,tmp[1]/total)\n",
    "    return dicts\n",
    "# generate the features using the features created before\n",
    "def feature_creation(train,test,bids):\n",
    "    #number of differents ips,urls\n",
    "    grouped = bids.groupby(['bidder_id','auction'])\n",
    "    app_mean = grouped.device.nunique().groupby(level=0).mean()\n",
    "    app_std = grouped.device.nunique().groupby(level=0).count()\n",
    "    app_max = grouped.device.nunique().groupby(level=0).max()\n",
    "    ip_mean = grouped.ip.nunique().groupby(level=0).mean()\n",
    "    ip_std = grouped.ip.nunique().groupby(level=0).count()\n",
    "    ip_max = grouped.ip.nunique().groupby(level=0).max()\n",
    "    pays_mean = grouped.country.nunique().groupby(level=0).mean()\n",
    "    pays_std = grouped.country.nunique().groupby(level=0).count()\n",
    "    pays_max = grouped.country.nunique().groupby(level=0).max()\n",
    "    page_mean = grouped.url.nunique().groupby(level=0).mean()\n",
    "    page_std = grouped.url.nunique().groupby(level=0).count()\n",
    "    page_max = grouped.url.nunique().groupby(level=0).max()\n",
    "    df = []\n",
    "    for cle in app_mean.keys():\n",
    "        df.append({'bidder_id' : cle, 'app_mean': app_mean[cle], 'app_std': app_std[cle],\n",
    "    'app_max': app_max[cle], 'ip_mean': ip_mean[cle],\n",
    "    'ip_std': ip_std[cle],'ip_max': ip_max[cle],'pays_mean': pays_mean[cle],'pays_std': pays_std[cle],'pays_max': pays_max[cle],\n",
    "    'page_mean': page_mean[cle],'page_std': page_std[cle],'page_max': page_max[cle]})\n",
    "    pd.DataFrame(df).to_csv('res/nb_uniques.csv', index=False)\n",
    "    df = []\n",
    "    return\n",
    "    #hour in the day for the humans and for each country \n",
    "    human = train[train.outcome==0]\n",
    "    bots = train[train.outcome==1]\n",
    "    human_bids = bids[bids[\"bidder_id\"].isin(human[\"bidder_id\"])]\n",
    "    robot_bids = bids[bids[\"bidder_id\"].isin(bots[\"bidder_id\"])]\n",
    "    show_stats = False\n",
    "    if show_stats:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sn\n",
    "        %matplotlib inline\n",
    "        countries = bids[\"country\"].unique()\n",
    "        for c in countries:\n",
    "            sub_d_h= human_bids[human_bids[\"country\"] == c]\n",
    "            sub_d_r= robot_bids[robot_bids[\"country\"] == c]\n",
    "            if len(sub_d_r)>1:\n",
    "                tmp_plot = sub_d_h.groupby(\"time\").count()\n",
    "                tmp_plot2 = sub_d_r.groupby(\"time\").count()\n",
    "                plt.plot(tmp_plot.index,tmp_plot,label=\"human\",alpha=0.7)\n",
    "                plt.plot(tmp_plot2.index,tmp_plot2,label=\"robot\",alpha=0.7)\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    #average moment of biding in the auction and win percentage\n",
    "    countries = {}\n",
    "    urls = {}\n",
    "    devices = {}\n",
    "    ips = {}\n",
    "    auctions = {}\n",
    "    merchandises = {}\n",
    "    times = {}\n",
    "    if os.path.exists(\"stats/urls.pkl\"):\n",
    "        with open('stats/urls.pkl', 'rb') as handle:\n",
    "            urls = pickle.load(handle)\n",
    "        with open('stats/countries.pkl', 'rb') as handle:\n",
    "            countries = pickle.load(handle)\n",
    "        with open('stats/devices.pkl', 'rb') as handle:\n",
    "            devices = pickle.load(handle)\n",
    "        with open('stats/merchandises.pkl', 'rb') as handle:\n",
    "            merchandises = pickle.load(handle)\n",
    "        with open('stats/auctions.pkl', 'rb') as handle:\n",
    "            auctions = pickle.load(handle)\n",
    "        with open('stats/times.pkl', 'rb') as handle:\n",
    "            times = pickle.load(handle)\n",
    "        print(len(auctions),len(times),len(merchandises),len(devices),len(countries),len(urls))\n",
    "    else:\n",
    "        to_do = len(bids)\n",
    "        bots_values = bots[\"bidder_id\"].values\n",
    "        #basics stats\n",
    "        for i,acc in bids.iterrows():\n",
    "            url = acc[\"url\"]\n",
    "            country = acc[\"country\"]\n",
    "            device = acc[\"device\"]\n",
    "            bid = acc[\"auction\"]\n",
    "            merchan = acc[\"merchandise\"]\n",
    "            time = acc[\"time\"]\n",
    "            cle = acc[\"bidder_id\"]\n",
    "            bot = cle in bots_values\n",
    "            if url not in urls:\n",
    "                urls[url] = [0,0]\n",
    "            if country not in countries:\n",
    "                countries[country] = [0,0]\n",
    "            if device not in devices:\n",
    "                devices[device] = [0,0]\n",
    "            if bid not in auctions:\n",
    "                auctions[bid] = [0,0]\n",
    "            if merchan not in merchandises:\n",
    "                merchandises[merchan] = [0,0]\n",
    "            if time not in times:\n",
    "                times[time] = [0,0]\n",
    "            if bot:\n",
    "                urls[url][0] +=1\n",
    "                countries[country][0] +=1\n",
    "                devices[device][0] +=1\n",
    "                merchandises[merchan][0] +=1\n",
    "                auctions[bid][0] +=1\n",
    "                times[time][0] +=1\n",
    "            else:\n",
    "                urls[url][1] +=1\n",
    "                countries[country][1] +=1\n",
    "                devices[device][1] +=1\n",
    "                merchandises[merchan][1] +=1\n",
    "                auctions[bid][1] +=1\n",
    "                times[time][1] +=1 \n",
    "            to_do -= 1\n",
    "            if to_do % 100000 ==0:\n",
    "                print(to_do)\n",
    "        urls = normalize(urls)\n",
    "        countries = normalize(countries)\n",
    "        devices = normalize(devices)\n",
    "        merchandises = normalize(merchandises)\n",
    "        auctions = normalize(auctions)\n",
    "        times = normalize(times)\n",
    "        with open('stats/urls.pkl', 'wb') as handle:\n",
    "            pickle.dump(urls, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/countries.pkl', 'wb') as handle:\n",
    "            pickle.dump(countries, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/devices.pkl', 'wb') as handle:\n",
    "            pickle.dump(devices, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/merchandises.pkl', 'wb') as handle:\n",
    "            pickle.dump(merchandises, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/auctions.pkl', 'wb') as handle:\n",
    "            pickle.dump(auctions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('stats/times.pkl', 'wb') as handle:\n",
    "            pickle.dump(times, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    grouped_person = bids.groupby(['bidder_id'])\n",
    "    url_score = {}\n",
    "    country_score = {}\n",
    "    merchan_score = {}\n",
    "    devices_score = {}\n",
    "    auct_score = {}\n",
    "    times_score = {}\n",
    "    remaining = len(grouped_person)\n",
    "    print(\"TO DO : \",remaining)\n",
    "    bots_values = bots[\"bidder_id\"].values\n",
    "    for bides in grouped_person:\n",
    "        sub_data= bides[1]\n",
    "        for i,acc in sub_data.iterrows():\n",
    "            cle = acc[\"bidder_id\"]\n",
    "            bot = cle in bots_values\n",
    "            if cle not in url_score:\n",
    "                url_score[cle] = urls[acc[\"url\"]][int(bot)]\n",
    "            if cle not in country_score:\n",
    "                cle_c = acc[\"country\"]\n",
    "                if acc[\"country\"] != \"nan\":\n",
    "                    cle_c = \"in\"\n",
    "                country_score[cle] = countries[cle_c][int(bot)]\n",
    "            if cle not in merchan_score:\n",
    "                merchan_score[cle] = merchandises[acc[\"merchandise\"]][int(bot)]\n",
    "            if cle not in devices_score:\n",
    "                devices_score[cle] = devices[acc[\"device\"]][int(bot)]\n",
    "            if cle not in auct_score:\n",
    "                auct_score[cle] = auctions[acc[\"auction\"]][int(bot)]\n",
    "            if cle not in times_score:\n",
    "                times_score[cle] = times[acc[\"time\"]][int(bot)]\n",
    "        url_score[cle] = url_score[cle]  /float(len(sub_data))\n",
    "        country_score[cle] = country_score[cle]  /float(len(sub_data))\n",
    "        devices_score[cle] = devices_score[cle]  /float(len(sub_data))\n",
    "        merchan_score[cle] = merchan_score[cle]  /float(len(sub_data))\n",
    "        auct_score[cle] = auct_score[cle]  /float(len(sub_data))\n",
    "        times_score[cle] = times_score[cle]  /float(len(sub_data))\n",
    "        if remaining % 500 ==0:\n",
    "            print(remaining)\n",
    "        remaining -=1\n",
    "    df  = []\n",
    "    for cle in url_score.keys():\n",
    "        df.append({'bidder_id' : cle, 'url_score': url_score[cle], 'country_score': country_score[cle],\n",
    "    'device_score': devices_score[cle], 'merchan_score': merchan_score[cle],\n",
    "    'zauc_score': auct_score[cle],'time_score': times_score[cle]})\n",
    "    pd.DataFrame(df).to_csv('res/scores.csv', index=False)\n",
    "    \n",
    "    #to do : total number of bids, max nombre de bids dans une fentre de 15 minutes\n",
    "    #nombre de bids pour chacun des jours\n",
    "    '''\n",
    "    heure moyen de bid\n",
    "    number of simulatneous bids\n",
    "    est ce que c'est une heire normale (calculer pour chaque pays fenetre la plus utilisee dans la journee)\n",
    "    appartenir a url ? 'vasstdc27m7nks3(proba)\n",
    "    '''\n",
    "recreate = False\n",
    "if recreate:\n",
    "    feature_creation(train,test,bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate new features :\n",
    "from collections import Counter\n",
    "def new_features(train,test,bids):\n",
    "    countries= bids.country.unique()\n",
    "    countries_nb = {}\n",
    "    for c in countries:\n",
    "        countries_nb[c] = bids[bids[\"country\"] == c].bidder_id.value_counts()\n",
    "    #consecutive bids\n",
    "    tmp = bids.groupby([\"bidder_id\"]).time\n",
    "    max_four = {}\n",
    "    max_five= {}\n",
    "    max_six = {}\n",
    "    remaining = len(tmp)\n",
    "    consevuctive_bids_mean = {}\n",
    "    consevuctive_bids_min = {}\n",
    "    consevuctive_bids_std = {}\n",
    "    for d in tmp:\n",
    "        cle = d[0]\n",
    "        sub_data= d[1]\n",
    "        sub_data.sort()\n",
    "        four = np.max(Counter([str(nb)[:4] for nb in sub_data]).values())\n",
    "        five = np.max(Counter([str(nb)[:5] for nb in sub_data]).values())\n",
    "        six = np.max(Counter([str(nb)[:6] for nb in sub_data]).values())\n",
    "        diff = np.ediff1d(sub_data)\n",
    "        if len(diff)>0:\n",
    "            consevuctive_bids_mean[cle] = np.mean(diff)\n",
    "            consevuctive_bids_min[cle] = np.min(diff)\n",
    "            consevuctive_bids_std[cle]= np.std(diff)\n",
    "        max_four[cle] = four\n",
    "        max_five[cle] = five\n",
    "        max_six[cle] = six\n",
    "        if remaining % 1000 ==0:\n",
    "            print(remaining)\n",
    "        remaining -=1\n",
    "    ips_india_user = bids[(bids[\"country\"] == \"in\")].groupby([\"bidder_id\"]).ip.nunique()\n",
    "    ips_per_user = (bids.groupby([\"bidder_id\"]).ip.nunique())\n",
    "    unique_time_user = (bids.groupby([\"bidder_id\"]).time.nunique())\n",
    "    device_per_user = (bids.groupby([\"bidder_id\"]).device.nunique())\n",
    "    url_per_user = (bids.groupby([\"bidder_id\"]).url.nunique())\n",
    "    total_auction = bids.groupby(\"bidder_id\").auction.count()\n",
    "    total_bids = bids[\"bidder_id\"].value_counts()\n",
    "    #bid in each country\n",
    "    merchandises = bids.merchandise.unique()\n",
    "    merchan_nb = {}\n",
    "    for m in merchandises:\n",
    "        merchan_nb[m] = bids[bids[\"merchandise\"] == m].bidder_id.value_counts()\n",
    "    df = []\n",
    "    for c in total_bids.keys():\n",
    "        tmp = {'bidder_id' : c,  \"ips_per_user\" : ips_per_user[c], \"device_user\" : device_per_user[c],\n",
    "                  \"unq_time_user\" : unique_time_user[c], \"url_user\" : url_per_user[c]}\n",
    "        if c in ips_india_user:\n",
    "            tmp[\"ips_india\"] = ips_india_user[c]\n",
    "        else:\n",
    "            tmp[\"ips_india\"] = 0\n",
    "        if c in total_auction:\n",
    "            tmp[\"total_ac\"] = total_auction[c]\n",
    "        else:\n",
    "            tmp[\"total_ac\"] = 0\n",
    "        if c in total_bids:\n",
    "            tmp[\"total_bids\"] = total_bids[c]\n",
    "        else:\n",
    "            tmp[\"total_bids\"] = 0\n",
    "        for count in countries:\n",
    "            if c in countries_nb[count]:\n",
    "                tmp[str(count)] = countries_nb[count][c]\n",
    "            else:\n",
    "                tmp[str(count)] = 0\n",
    "        for count in merchan_nb.keys():\n",
    "            if c in merchan_nb[count]:\n",
    "                tmp[str(count)] = merchan_nb[count][c]\n",
    "            else:\n",
    "                tmp[str(count)] = 0\n",
    "        if c in consevuctive_bids_mean:\n",
    "            tmp[\"consec_bids_mean\"] = consevuctive_bids_mean[c]\n",
    "            tmp[\"consec_bids_min\"] = consevuctive_bids_min[c]\n",
    "            tmp[\"consec_bids_std\"] = consevuctive_bids_std[c]\n",
    "        if c in max_four:\n",
    "            tmp[\"max_four\"] = max_four[c]\n",
    "            tmp[\"max_five\"] = max_five[c]\n",
    "            tmp[\"max_six\"] = max_six[c]\n",
    "        df.append(tmp)\n",
    "    pd.DataFrame(df).to_csv('res/newss_stats.csv', index=False)        \n",
    "\n",
    "#new_features(train,test,bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4630,)\n",
      "(1984,)\n"
     ]
    }
   ],
   "source": [
    "def load_all(train,test,bids):\n",
    "    bids_numbers = pd.read_csv('res/bids_number.csv')\n",
    "    himself_time = pd.read_csv('res/himslef_time.csv')\n",
    "    other = pd.read_csv('res/other_stats.csv')\n",
    "    scores = pd.read_csv('res/scores.csv')\n",
    "    time_auction = pd.read_csv('res/time_auction.csv')\n",
    "    nb_uniques = pd.read_csv('res/nb_uniques.csv')\n",
    "    new_feats = pd.read_csv(\"res/newss_stats.csv\")\n",
    "    #test file\n",
    "    y_train = train[\"outcome\"]\n",
    "    #new train representation\n",
    "    new_train = train[\"bidder_id\"].to_frame()\n",
    "    new_train = pd.merge(new_train,bids_numbers,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = pd.merge(new_train,himself_time,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = pd.merge(new_train,other,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = pd.merge(new_train,scores,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = pd.merge(new_train,time_auction,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = pd.merge(new_train,nb_uniques,on=\"bidder_id\",how=\"left\")\n",
    "    new_train = pd.merge(new_train,new_feats,on=\"bidder_id\",how=\"left\")\n",
    "    new_train= new_train.fillna(new_train.mean())\n",
    "    #new test\n",
    "    new_test = test[\"bidder_id\"].to_frame()\n",
    "    new_test = pd.merge(new_test,bids_numbers,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = pd.merge(new_test,himself_time,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = pd.merge(new_test,other,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = pd.merge(new_test,scores,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = pd.merge(new_test,time_auction,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = pd.merge(new_test,nb_uniques,on=\"bidder_id\",how=\"left\")\n",
    "    new_test = pd.merge(new_test,new_feats,on=\"bidder_id\",how=\"left\")\n",
    "    new_test= new_test.fillna(new_test.mean())\n",
    "    #new_train = new_train.drop(\"max_number_bids\",axis=1)\n",
    "    #new_test = new_test.drop(\"max_number_bids\",axis=1)\n",
    "    new_train = new_train.drop([\"time_score\",\"url_score\",\"merchan_score\",\"zauc_score\",\"device_score\",\"country_score\"],axis=1)\n",
    "    new_test = new_test.drop([\"time_score\",\"url_score\",\"merchan_score\",\"zauc_score\",\"device_score\",\"country_score\"],axis=1)\n",
    "    to_drop = [\"pays_max\",\"min_number_bids\",\"pays_max\"]\n",
    "    new_train = new_train.drop(to_drop,axis=1)\n",
    "    new_test = new_test.drop(to_drop,axis=1)\n",
    "    return new_train,new_test,y_train\n",
    "\n",
    "def test_loading(train,test,bids):\n",
    "    time_auction = pd.read_csv('res/time_auction.csv')\n",
    "    auctions_stats = pd.read_csv('res/stats_test.csv')\n",
    "    auctions_stats_simple = pd.read_csv(\"res/stats_test_simple.csv\")\n",
    "    auctions_stats = auctions_stats.groupby('bidder_id',as_index=False).mean()\n",
    "    '''print(auctions_stats.bidder_id)\n",
    "    print(auctions_stats_simple.bidder_id)\n",
    "    auctions_stats.rename(columns=lambda x: x+str(\"_c\"), inplace=True)\n",
    "    auctions_stats.rename(columns={\"bidder_id_c\":\"bidder_id\"},inplace=True)'''\n",
    "    auctions_stats = pd.merge(auctions_stats,time_auction,on=\"bidder_id\")\n",
    "    auctions_stats_simple = pd.merge(auctions_stats_simple,auctions_stats,on=\"bidder_id\")\n",
    "    new_train = train[[\"bidder_id\",\"outcome\"]].copy()\n",
    "    #y_train = train[\"outcome\"]\n",
    "    new_test = test[[\"bidder_id\"]].copy()\n",
    "    new_train = pd.merge(new_train,auctions_stats_simple,on=\"bidder_id\")\n",
    "    y_train = new_train[\"outcome\"]\n",
    "    #new_train = new_train.drop(\"outcome\",axis=1)\n",
    "    new_test = pd.merge(new_test,auctions_stats_simple,on=\"bidder_id\")\n",
    "    #new_test= new_test.fillna(mean_s)\n",
    "    #new_train= new_train.fillna(mean_s)\n",
    "    return new_train,new_test,y_train\n",
    "\n",
    "X_train,X_test,y_train = test_loading(train,test,bids)\n",
    "print(X_test.bidder_id.unique().shape)\n",
    "print(X_train.bidder_id.unique().shape)\n",
    "#X_trXain,X_test,y_train = load_all(train,test,bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(\"debug_train.csv\",index=False)\n",
    "X_test.to_csv(\"debug_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "0.852447089947\n",
      "-------------------------\n",
      "0.874935897436\n",
      "-------------------------\n",
      "0.892383107089\n",
      "-------------------------\n",
      "0.880011520737\n",
      "-------------------------\n",
      "0.889191965939\n",
      "-------------------------\n",
      "0.900084033613\n",
      "-------------------------\n",
      "0.913725300687\n",
      "-------------------------\n",
      "0.907945470504\n",
      "-------------------------\n",
      "0.927075163399\n",
      "-------------------------\n",
      "0.927273553419\n",
      "-------------------------\n",
      "0.937328868315\n",
      "-------------------------\n",
      "0.907293711473\n",
      "-------------------------\n",
      "0.926977607399\n",
      "-------------------------\n",
      "0.918925357193\n",
      "-------------------------\n",
      "0.918564674097\n"
     ]
    }
   ],
   "source": [
    "# first ml algo\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "def to_kaggle(X_train,X_test,y_train):\n",
    "    test_ids = X_test['bidder_id']\n",
    "    X_test = X_test.drop(labels=['bidder_id'], axis=1, inplace=False)\n",
    "    predictions = predict(X_train, X_test, y_train)\n",
    "    sub = pd.read_csv('sampleSubmission.csv')\n",
    "    result = pd.DataFrame()\n",
    "    result['bidder_id'] = test_ids\n",
    "    result['outcome'] = predictions\n",
    "    sub = sub.merge(result, on='bidder_id', how='left')\n",
    "    # Fill missing values with mean\n",
    "    sub.fillna(0.0511674, inplace=True)\n",
    "    sub.drop('prediction', 1, inplace=True)\n",
    "    sub.to_csv('submission/random.csv', index=False, header=['bidder_id', 'prediction'])\n",
    "\n",
    "def predict(X_train, X_test, y_train):\n",
    "    clf = RandomForestClassifier(n_estimators=160,max_depth=8, max_features = 35 , random_state=9,criterion='entropy')\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict_proba(X_test)[:, 1]\n",
    "    return predictions\n",
    "\n",
    "def predict_model(X_train, X_test, y_train,model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_test)[:, 1]\n",
    "    return predictions\n",
    "\n",
    "def cross_val_score(train,ytrain):\n",
    "    kf = StratifiedKFold(y=ytrain, n_folds=10)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "        y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "        predictions = predict(X_train, X_test, y_train)\n",
    "        scores.append(roc_auc_score(y_test, predictions))\n",
    "    print np.mean(scores)\n",
    "def grid_seach(train,ytrain):\n",
    "    model = RandomForestClassifier(max_depth=8,random_state=9,criterion='entropy') \n",
    "    parameters = {'n_estimators':[50,100,150,200,250,300], 'max_features':[6,8,10,20,25,30,25,40,45,50,60,70,80]}\n",
    "    clf = GridSearchCV(model, parameters,cv=10,n_jobs=-1,scoring='roc_auc')\n",
    "    clf.fit(train, y_train)\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    with open('mode_res.pickle', 'wb') as handle:\n",
    "        pickle.dump(clf.grid_scores_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def test_models(train,ytrain):\n",
    "    kf = StratifiedKFold(y=ytrain, n_folds=10)\n",
    "    models = [RandomForestClassifier(n_estimators=160,max_depth=8, max_features = 35 , random_state=9,criterion='entropy'),AdaBoostClassifier(),\n",
    "             GradientBoostingClassifier(),KNeighborsClassifier(),AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=200,max_depth=8, max_features = 35 , random_state=9,criterion='entropy')),\n",
    "             SVC(kernel=\"poly\",probability=True),SVC(probability=True),DecisionTreeClassifier()]\n",
    "    res_per_models = {}\n",
    "    for m in models:\n",
    "        print(\"-------------------------\")\n",
    "        print(str(m))\n",
    "        start = time.time()\n",
    "        scores = []\n",
    "        for train_index, test_index in kf:\n",
    "            X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "            y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "            predictions = predict_model(X_train, X_test, y_train,m)\n",
    "            scores.append(roc_auc_score(y_test, predictions))\n",
    "        print np.mean(scores)\n",
    "        end = time.time()\n",
    "        res_per_models[str(m)] = (np.mean(scores),end)\n",
    "    with open('multi_modles.pickle', 'wb') as handle:\n",
    "        pickle.dump(res_per_models, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def train_size_impact(train,ytrain):\n",
    "    model = RandomForestClassifier(n_estimators=160,max_depth=8, max_features = 35 , random_state=9,criterion='entropy')\n",
    "    res_per_models = []\n",
    "    taille = np.linspace(0.15,1,15)\n",
    "    for t in taille:\n",
    "        print(\"-------------------------\")\n",
    "        start = time.time()\n",
    "        scores = []\n",
    "        X_tmp = train.copy()\n",
    "        X_tmp[\"ppppp\"] = ytrain\n",
    "        X_tmp = X_tmp.sample(n=int(len(ytrain)*t))\n",
    "        y_tmp = X_tmp[\"ppppp\"]\n",
    "        X_tmp = X_tmp.drop(\"ppppp\",axis=1)\n",
    "        kf = StratifiedKFold(y=y_tmp, n_folds=10)\n",
    "        for train_index, test_index in kf:\n",
    "            X_train, X_test = X_tmp.iloc[train_index], X_tmp.iloc[test_index]\n",
    "            y_train, y_test = y_tmp.iloc[train_index], y_tmp.iloc[test_index]\n",
    "            predictions = predict_model(X_train, X_test, y_train,model)\n",
    "            scores.append(roc_auc_score(y_test, predictions))\n",
    "        print np.mean(scores)\n",
    "        res_per_models.append(np.mean(scores))\n",
    "    with open('modele_percent.pickle', 'wb') as handle:\n",
    "        pickle.dump(res_per_models, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "train = pd.read_csv(\"debug_train.csv\")\n",
    "train['outcome'] = train['outcome'].astype(int)\n",
    "ytrain = train['outcome']\n",
    "train.drop('outcome', 1, inplace=True)\n",
    "train.drop(labels=['bidder_id'], axis=1, inplace=True)\n",
    "test = pd.read_csv(\"debug_test.csv\")\n",
    "\n",
    "'''\n",
    "kf = StratifiedKFold(y=ytrain, n_folds=10)\n",
    "scores = []\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    predictions = predict(X_train, X_test, y_train)\n",
    "    scores.append(roc_auc_score(y_test, predictions))\n",
    "print np.mean(scores)'''\n",
    "#grid_seach(train,ytrain)\n",
    "#to_kaggle(train,test,ytrain)\n",
    "#test_models(train,ytrain)\n",
    "train_size_impact(train,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(result, interpolation='nearest', cmap=plt.cm.hot)\n",
    "plt.xlabel('Max features')\n",
    "plt.ylabel('Number of estimators')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len([5,7,10,12])), [5,7,10,12], rotation=45)\n",
    "plt.yticks(np.arange(len([10,50,60,80])), [10,50,60,80])\n",
    "plt.title('Grid search : RMSLE score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Score : ', 0.99984551697317658)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 447 and input n_features is 446 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e8e43f7b89a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     print(\"prediction\",np.sum(clf.predict(X_test_bis)))'''\n\u001b[1;32m     52\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mfill_predcitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-e8e43f7b89a4>\u001b[0m in \u001b[0;36mfill_predcitions\u001b[0;34m(X_train, X_test, y_train)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_bis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_bis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not null : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \"\"\"\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[0;32m--> 668\u001b[0;31m                        for estimator in self.estimators_)\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((estimator,))\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[0;32m--> 668\u001b[0;31m                        for estimator in self.estimators_)\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_samme_proba\u001b[0;34m(estimator, n_classes, X)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \"\"\"\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# Displace zero probabilities so the log is defined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \"\"\"\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    353\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    401\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 447 and input n_features is 446 "
     ]
    }
   ],
   "source": [
    "# first ml algo\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "def cross_val(X_train,y_train):\n",
    "    X_train = X_train.drop(\"bidder_id\",axis=1)\n",
    "    X_train_bis = X_train.values\n",
    "    y_train_bis = y_train.astype(int).values\n",
    "    predictions = []\n",
    "    kf = StratifiedKFold(y=y_train_bis, n_folds=10)\n",
    "    clf = RandomForestClassifier(n_estimators=160,max_depth=8, max_features = 35 , random_state=9,criterion='entropy')\n",
    "    for train_index, test_index in kf:\n",
    "        X_train_2, X_test_2 = X_train_bis[train_index], X_train_bis[test_index]\n",
    "        y_train_2, y_test_2 = y_train_bis[train_index], y_train_bis[test_index]\n",
    "        clf.fit(X_train_2,y_train_2)\n",
    "        prediction = clf.predict_proba(X_test_2)[:, 1]\n",
    "        predictions.append(roc_auc_score(y_test_2, prediction))\n",
    "        #print(\"Nb not zeros : \", np.sum(prediction),prediction.shape)\n",
    "        #print(\"test debug \", np.sum(clf.predict(X_test_bis)),X_test_bis.shape)\n",
    "    print(\"Score : \", np.mean(predictions))\n",
    "    #print(sorted(zip(clf.feature_importances_,X_train.columns)))\n",
    "    '''selector = RFECV(clf, cv=15,n_jobs=-1)\n",
    "    selector = selector.fit(X_train_bis, y_train_bis)\n",
    "    print(zip(selector.support_,X_train.columns))\n",
    "    print(selector.ranking_)\n",
    "    print(selector.grid_scores_)'''\n",
    "    \n",
    "\n",
    "def fill_predcitions(X_train,X_test,y_train):\n",
    "    X_train_bis = X_train.drop(\"bidder_id\",axis=1).values\n",
    "    X_test_bis = X_test.drop(\"bidder_id\",axis=1).values\n",
    "    y_train_bis = y_train.astype(int).values\n",
    "    model = RandomForestClassifier(n_estimators=160,max_depth=8, max_features = 35 , random_state=9,criterion='entropy')\n",
    "    clf = AdaBoostClassifier(base_estimator=model, n_estimators=25)\n",
    "    clf.fit(X_train_bis,y_train_bis)\n",
    "    prediction = clf.predict(X_test_bis)\n",
    "    prediction = prediction.astype(float)\n",
    "    print(\"Not null : \", np.sum(prediction),len(prediction))\n",
    "    submi = pd.read_csv('sampleSubmission.csv')\n",
    "    #submi[\"prediction\"] = 0.05\n",
    "    submi = submi.drop(\"prediction\",axis=1)\n",
    "    X_test[\"prediction\"] = prediction\n",
    "    submi = pd.merge(submi,X_test[[\"bidder_id\",\"prediction\"]],on=\"bidder_id\",how=\"left\")\n",
    "    submi = submi[[\"bidder_id\",\"prediction\"]]\n",
    "    submi.fillna(0.0511674, inplace=True)\n",
    "    #submi = pd.merge(submi,prediction)\n",
    "    submi.to_csv('submission/random.csv', index=False)\n",
    "    '''print(X_test.shape)\n",
    "    print(clf.fit(X_train_bis,y_train_bis))\n",
    "    print(\"prediction\",np.sum(clf.predict(X_test_bis)))'''\n",
    "cross_val(X_train,y_train)\n",
    "fill_predcitions(X_train,X_test,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "print(X_train.columns)\n",
    "X_train_bis = X_train.drop(\"bidder_id\",axis=1).values\n",
    "y_train_bis = y_train.astype(int).values\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_bis,y_train_bis)\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tools import *\n",
    "\n",
    "def stats_country(sub_data,line):\n",
    "    dicts = sub_data['merchandise'].value_counts()\n",
    "    for typ, value in dicts.iteritems():\n",
    "        line[typ] = value\n",
    "    for c in sub_data['country'].unique():\n",
    "        line[str(c)] = 1\n",
    "def test_apply(data):\n",
    "    line = {\"test\" : 5}\n",
    "    return pd.Series(line)\n",
    "def basic_stats(sub_data):\n",
    "    t1 = sub_data.shape\n",
    "    return t1[0]\n",
    "def features_times(bids):\n",
    "    #tmp_copye = bids.copy()\n",
    "    #tmp_copye = tmp_copye[tmp_copye[\"bidder_id\"]==\"0051aef3fdeacdadba664b9b3b07e04e4coc6\"]\n",
    "    bidders = bids.groupby(['bidder_id', 'auction'])\n",
    "    df = []\n",
    "    for bid in bidders:\n",
    "        sub_data = bid[1]\n",
    "        time_moving = np.ediff1d(sub_data['time'])\n",
    "        if len(time_moving)>0:\n",
    "            min_v = np.min(time_moving)\n",
    "            mean_v = np.mean(time_moving)\n",
    "            std_v = np.std(time_moving)\n",
    "            median_v = np.median(time_moving)\n",
    "            zeros_count = len(time_moving) - np.count_nonzero(time_moving)\n",
    "        else:\n",
    "            min_v,mean_v,std_v,median_v,zeros_count = 0.0,0.0,0.0,0.0,0.0\n",
    "        line = dict.fromkeys(categories, 0)\n",
    "        line.update(dict.fromkeys(countries_list, 0))\n",
    "        line[\"bidder_id\"] = bid[0][0]\n",
    "        line[\"auction\"] = bid[0][1]\n",
    "        #line[\"min_auction\"] = min_v\n",
    "        line[\"mean_auction\"] = mean_v\n",
    "        line[\"std_auction\"] = std_v\n",
    "        line[\"median_auction\"] = median_v\n",
    "        line[\"zeros_count\"] = zeros_count\n",
    "        #ips\n",
    "        line['ips_auction'] = basic_stats(sub_data['ip'].unique())\n",
    "        #urls\n",
    "        line['url_auction'] = basic_stats(sub_data['url'].unique())\n",
    "        #device\n",
    "        line['device_auction'] = basic_stats(sub_data['device'].unique())\n",
    "        #countries\n",
    "        line['country_auction'] = basic_stats(sub_data['country'].unique())\n",
    "        #bids\n",
    "        line['bid_auction'] = sub_data.shape[0]\n",
    "        #merchandises\n",
    "        line['merchan_auction'] = basic_stats(sub_data['merchandise'].unique())\n",
    "        stats_country(sub_data,line)\n",
    "        df.append(line)\n",
    "    pd.DataFrame(df).to_csv('res/stats_test.csv',index=False)\n",
    "    \n",
    "def features_times_simple(bids):\n",
    "    bids = pd.read_csv('bids.csv')\n",
    "    #tmp_bids = bids.copy()\n",
    "    #tmp_bids = tmp_bids[tmp_bids[\"bidder_id\"]==\"fa64831ab5ade55daee13f852c16b0a84ujt0\"]\n",
    "    bidders = bids.groupby(['bidder_id'])\n",
    "    df = []\n",
    "    for bid in bidders:\n",
    "        #print(np.mean(np.ediff1d((bid[1].time))))\n",
    "        sub_data = bid[1]\n",
    "        time_moving = np.ediff1d(sub_data['time'])\n",
    "        if len(time_moving)>0:\n",
    "            min_v = np.min(time_moving)\n",
    "            mean_v = np.mean(time_moving)\n",
    "            std_v = np.std(time_moving)\n",
    "            median_v = np.median(time_moving)\n",
    "            zeros_count = len(time_moving) - np.count_nonzero(time_moving)\n",
    "        else:\n",
    "            min_v,mean_v,std_v,median_v,zeros_count = 0.0,0.0,0.0,0.0,0.0\n",
    "        line = dict.fromkeys(categories, 0)\n",
    "        line.update(dict.fromkeys(countries_list, 0))\n",
    "        line[\"bidder_id\"] = bid[0]\n",
    "        #line[\"min_auction\"] = min_v\n",
    "        line[\"mean_auction\"] = mean_v\n",
    "        line[\"std_auction\"] = std_v\n",
    "        line[\"median_auction\"] = median_v\n",
    "        line[\"zeros_count\"] = zeros_count\n",
    "        #ips\n",
    "        line['ips_auction'] = basic_stats(sub_data['ip'].unique())\n",
    "        #urls\n",
    "        line['url_auction'] = basic_stats(sub_data['url'].unique())\n",
    "        #device\n",
    "        line['device_auction'] = basic_stats(sub_data['device'].unique())\n",
    "        #countries\n",
    "        line['auction_nb'] = sub_data['auction'].unique().shape[0]\n",
    "        line['country_auction'] = basic_stats(sub_data['country'].unique())\n",
    "        #bids\n",
    "        line['bid_auction'] = sub_data.shape[0]\n",
    "        #merchandises\n",
    "        line['merchan_auction'] = basic_stats(sub_data['merchandise'].unique())\n",
    "        stats_country(sub_data,line)\n",
    "        line['mean_auction_t'] = np.mean(sub_data['auction'].value_counts())\n",
    "        df.append(line)\n",
    "    pd.DataFrame(df).to_csv('res/stats_test_simple.csv',index=False)\n",
    "\n",
    "recreate= False\n",
    "if recreate:\n",
    "    features_times(bids)\n",
    "recreate2 = True\n",
    "if recreate2:\n",
    "    features_times_simple(bids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
